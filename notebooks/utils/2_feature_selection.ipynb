{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Feature Selection - Customer Churn Dataset\n",
    "\n",
    "This notebook performs extensive feature selection using multiple techniques:\n",
    "- Statistical Tests (Chi-Square, ANOVA, Mutual Information)\n",
    "- Filter Methods (Variance Threshold, Correlation)\n",
    "- Wrapper Methods (RFE, Sequential Feature Selection)\n",
    "- Embedded Methods (Lasso, Ridge, Tree-based Feature Importance)\n",
    "- Feature Importance from Multiple Models\n",
    "- Comprehensive Feature Ranking and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, f_oneway\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest, chi2, f_classif, mutual_info_classif,\n",
    "    VarianceThreshold, RFE, RFECV, SelectFromModel,\n",
    "    SequentialFeatureSelector\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization styles\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('customer_churn_dataset_with_date.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Percentage': (df.isnull().sum() / len(df)) * 100\n",
    "})\n",
    "print(missing_summary[missing_summary['Missing_Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for processing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Drop customer_id and Date as they're not predictive features\n",
    "df_processed = df_processed.drop(['customer_id', 'Date'], axis=1, errors='ignore')\n",
    "\n",
    "# Separate features and target\n",
    "X = df_processed.drop('churn', axis=1)\n",
    "y = df_processed['churn']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nChurn distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nChurn rate: {y.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Numerical features ({len(numerical_features)}): {numerical_features}\")\n",
    "print(f\"\\nCategorical features ({len(categorical_features)}): {categorical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# For numerical features: fill with median\n",
    "for col in numerical_features:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        X[col].fillna(X[col].median(), inplace=True)\n",
    "        print(f\"Filled {col} missing values with median: {X[col].median():.3f}\")\n",
    "\n",
    "# For categorical features: fill with mode\n",
    "for col in categorical_features:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        X[col].fillna(X[col].mode()[0], inplace=True)\n",
    "        print(f\"Filled {col} missing values with mode: {X[col].mode()[0]}\")\n",
    "\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(X.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "X_encoded = X.copy()\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    X_encoded[col] = le.fit_transform(X[col])\n",
    "    label_encoders[col] = le\n",
    "    print(f\"\\nEncoded {col}:\")\n",
    "    print(f\"  Original values: {X[col].unique()}\")\n",
    "    print(f\"  Encoded values: {X_encoded[col].unique()}\")\n",
    "\n",
    "print(f\"\\nEncoded dataset shape: {X_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train-test split for model-based feature selection\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "print(f\"\\nTraining set churn rate: {y_train.mean()*100:.2f}%\")\n",
    "print(f\"Test set churn rate: {y_test.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features for certain algorithms\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for easier handling\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"Data scaled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistical Tests for Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Chi-Square Test (for categorical features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-Square Test\n",
    "print(\"Chi-Square Test for All Features\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "chi2_scores = []\n",
    "chi2_pvalues = []\n",
    "\n",
    "for col in X_encoded.columns:\n",
    "    # Ensure non-negative values for chi2 test\n",
    "    X_positive = X_encoded[[col]] - X_encoded[[col]].min() + 0.01\n",
    "    \n",
    "    selector = SelectKBest(score_func=chi2, k='all')\n",
    "    selector.fit(X_positive, y)\n",
    "    \n",
    "    chi2_scores.append(selector.scores_[0])\n",
    "    chi2_pvalues.append(selector.pvalues_[0])\n",
    "\n",
    "chi2_results = pd.DataFrame({\n",
    "    'Feature': X_encoded.columns,\n",
    "    'Chi2_Score': chi2_scores,\n",
    "    'P_Value': chi2_pvalues,\n",
    "    'Significant': ['Yes' if p < 0.05 else 'No' for p in chi2_pvalues]\n",
    "}).sort_values('Chi2_Score', ascending=False)\n",
    "\n",
    "print(chi2_results)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(chi2_results['Feature'], chi2_results['Chi2_Score'], color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Chi-Square Score', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.title('Chi-Square Test Scores for All Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ANOVA F-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA F-Test\n",
    "print(\"ANOVA F-Test for All Features\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "selector_f = SelectKBest(score_func=f_classif, k='all')\n",
    "selector_f.fit(X_train, y_train)\n",
    "\n",
    "f_scores = selector_f.scores_\n",
    "f_pvalues = selector_f.pvalues_\n",
    "\n",
    "f_results = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'F_Score': f_scores,\n",
    "    'P_Value': f_pvalues,\n",
    "    'Significant': ['Yes' if p < 0.05 else 'No' for p in f_pvalues]\n",
    "}).sort_values('F_Score', ascending=False)\n",
    "\n",
    "print(f_results)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(f_results['Feature'], f_results['F_Score'], color='lightcoral', edgecolor='black')\n",
    "plt.xlabel('F-Score', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.title('ANOVA F-Test Scores for All Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutual Information\n",
    "print(\"Mutual Information for All Features\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "mi_scores = mutual_info_classif(X_train, y_train, random_state=RANDOM_STATE)\n",
    "\n",
    "mi_results = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'MI_Score': mi_scores\n",
    "}).sort_values('MI_Score', ascending=False)\n",
    "\n",
    "print(mi_results)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(mi_results['Feature'], mi_results['MI_Score'], color='lightgreen', edgecolor='black')\n",
    "plt.xlabel('Mutual Information Score', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.title('Mutual Information Scores for All Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filter Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance Threshold\n",
    "print(\"Variance Threshold Analysis\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate variance for each feature\n",
    "variances = X_train.var().sort_values(ascending=False)\n",
    "variance_df = pd.DataFrame({\n",
    "    'Feature': variances.index,\n",
    "    'Variance': variances.values\n",
    "})\n",
    "\n",
    "print(variance_df)\n",
    "\n",
    "# Apply variance threshold (e.g., 0.01)\n",
    "threshold = 0.01\n",
    "selector_var = VarianceThreshold(threshold=threshold)\n",
    "selector_var.fit(X_train)\n",
    "\n",
    "low_variance_features = X_train.columns[~selector_var.get_support()].tolist()\n",
    "print(f\"\\nFeatures with variance < {threshold}:\")\n",
    "print(low_variance_features if low_variance_features else \"None\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(variance_df['Feature'], variance_df['Variance'], color='purple', alpha=0.7, edgecolor='black')\n",
    "plt.axhline(threshold, color='red', linestyle='--', linewidth=2, label=f'Threshold = {threshold}')\n",
    "plt.xlabel('Features', fontsize=12)\n",
    "plt.ylabel('Variance', fontsize=12)\n",
    "plt.title('Feature Variance Analysis', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target\n",
    "print(\"Correlation with Target Variable\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate correlation with target\n",
    "correlations = X_train.corrwith(y_train).abs().sort_values(ascending=False)\n",
    "corr_df = pd.DataFrame({\n",
    "    'Feature': correlations.index,\n",
    "    'Abs_Correlation': correlations.values\n",
    "})\n",
    "\n",
    "print(corr_df)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(corr_df['Feature'], corr_df['Abs_Correlation'], color='orange', edgecolor='black')\n",
    "plt.xlabel('Absolute Correlation with Churn', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.title('Feature Correlation with Target Variable', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-to-feature correlation (multicollinearity check)\n",
    "print(\"\\nFeature-to-Feature Correlation Matrix\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "corr_matrix = X_train.corr()\n",
    "\n",
    "# Find highly correlated feature pairs\n",
    "high_corr_pairs = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.8:\n",
    "            high_corr_pairs.append((\n",
    "                corr_matrix.columns[i], \n",
    "                corr_matrix.columns[j], \n",
    "                corr_matrix.iloc[i, j]\n",
    "            ))\n",
    "\n",
    "print(\"Highly correlated feature pairs (|r| > 0.8):\")\n",
    "if high_corr_pairs:\n",
    "    for feat1, feat2, corr in high_corr_pairs:\n",
    "        print(f\"  {feat1} <-> {feat2}: {corr:.4f}\")\n",
    "else:\n",
    "    print(\"  None found\")\n",
    "\n",
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature-to-Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Wrapper Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE with Logistic Regression\n",
    "print(\"Recursive Feature Elimination (RFE) - Logistic Regression\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Determine optimal number of features using RFECV\n",
    "lr = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)\n",
    "rfecv = RFECV(estimator=lr, step=1, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "rfecv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Optimal number of features: {rfecv.n_features_}\")\n",
    "print(f\"\\nSelected features:\")\n",
    "selected_features_rfe = X_train.columns[rfecv.support_].tolist()\n",
    "print(selected_features_rfe)\n",
    "\n",
    "# Feature ranking\n",
    "rfe_ranking = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Ranking': rfecv.ranking_,\n",
    "    'Selected': rfecv.support_\n",
    "}).sort_values('Ranking')\n",
    "\n",
    "print(\"\\nFeature Rankings:\")\n",
    "print(rfe_ranking)\n",
    "\n",
    "# Plot number of features vs cross-validation scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), \n",
    "         rfecv.cv_results_['mean_test_score'], marker='o')\n",
    "plt.xlabel('Number of Features Selected', fontsize=12)\n",
    "plt.ylabel('Cross-Validation ROC-AUC Score', fontsize=12)\n",
    "plt.title('RFE: Number of Features vs CV Score', fontsize=14, fontweight='bold')\n",
    "plt.axvline(rfecv.n_features_, color='red', linestyle='--', \n",
    "            linewidth=2, label=f'Optimal: {rfecv.n_features_} features')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE with Random Forest\n",
    "print(\"\\nRecursive Feature Elimination (RFE) - Random Forest\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rfecv_rf = RFECV(estimator=rf, step=1, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "rfecv_rf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Optimal number of features: {rfecv_rf.n_features_}\")\n",
    "print(f\"\\nSelected features:\")\n",
    "selected_features_rfe_rf = X_train.columns[rfecv_rf.support_].tolist()\n",
    "print(selected_features_rfe_rf)\n",
    "\n",
    "# Feature ranking\n",
    "rfe_rf_ranking = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Ranking': rfecv_rf.ranking_,\n",
    "    'Selected': rfecv_rf.support_\n",
    "}).sort_values('Ranking')\n",
    "\n",
    "print(\"\\nFeature Rankings:\")\n",
    "print(rfe_rf_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Sequential Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Selection\n",
    "print(\"Sequential Feature Selection - Forward\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "lr_sfs = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)\n",
    "sfs = SequentialFeatureSelector(\n",
    "    lr_sfs, \n",
    "    n_features_to_select='auto',\n",
    "    direction='forward', \n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "sfs.fit(X_train_scaled, y_train)\n",
    "\n",
    "selected_features_sfs = X_train.columns[sfs.get_support()].tolist()\n",
    "print(f\"Number of selected features: {len(selected_features_sfs)}\")\n",
    "print(f\"\\nSelected features:\")\n",
    "print(selected_features_sfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Embedded Methods - Tree-Based Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Random Forest Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Feature Importance\n",
    "print(\"Random Forest Feature Importance\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(rf_importance)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(rf_importance['Feature'], rf_importance['Importance'], color='forestgreen', edgecolor='black')\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.title('Random Forest Feature Importance', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate baseline score\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(f\"\\nRandom Forest Test Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Random Forest Test ROC-AUC: {roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Gradient Boosting Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Feature Importance\n",
    "print(\"Gradient Boosting Feature Importance\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "gb_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': gb_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(gb_importance)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(gb_importance['Feature'], gb_importance['Importance'], color='dodgerblue', edgecolor='black')\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.title('Gradient Boosting Feature Importance', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Extra Trees Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Trees Feature Importance\n",
    "print(\"Extra Trees Feature Importance\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "et_model = ExtraTreesClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "et_model.fit(X_train, y_train)\n",
    "\n",
    "et_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': et_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(et_importance)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(et_importance['Feature'], et_importance['Importance'], color='crimson', edgecolor='black')\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.title('Extra Trees Feature Importance', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation Importance\n",
    "print(\"Permutation Importance (Random Forest)\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "perm_importance = permutation_importance(\n",
    "    rf_model, X_test, y_test, \n",
    "    n_repeats=10, \n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "perm_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance_Mean': perm_importance.importances_mean,\n",
    "    'Importance_Std': perm_importance.importances_std\n",
    "}).sort_values('Importance_Mean', ascending=False)\n",
    "\n",
    "print(perm_importance_df)\n",
    "\n",
    "# Visualize with error bars\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(perm_importance_df['Feature'], perm_importance_df['Importance_Mean'], \n",
    "         xerr=perm_importance_df['Importance_Std'], \n",
    "         color='mediumpurple', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Permutation Importance', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.title('Permutation Feature Importance (with std)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. L1 Regularization (Lasso) Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 Regularization - Lasso\n",
    "print(\"L1 Regularization (Lasso) Feature Selection\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Try different C values (inverse of regularization strength)\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "lasso_results = []\n",
    "\n",
    "for C in C_values:\n",
    "    lasso = LogisticRegression(penalty='l1', C=C, solver='liblinear', \n",
    "                               max_iter=1000, random_state=RANDOM_STATE)\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Count non-zero coefficients\n",
    "    n_selected = np.sum(lasso.coef_ != 0)\n",
    "    \n",
    "    # Calculate performance\n",
    "    train_score = lasso.score(X_train_scaled, y_train)\n",
    "    test_score = lasso.score(X_test_scaled, y_test)\n",
    "    \n",
    "    lasso_results.append({\n",
    "        'C': C,\n",
    "        'N_Features': n_selected,\n",
    "        'Train_Score': train_score,\n",
    "        'Test_Score': test_score\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nC = {C}:\")\n",
    "    print(f\"  Features selected: {n_selected}\")\n",
    "    print(f\"  Train accuracy: {train_score:.4f}\")\n",
    "    print(f\"  Test accuracy: {test_score:.4f}\")\n",
    "\n",
    "lasso_results_df = pd.DataFrame(lasso_results)\n",
    "\n",
    "# Use best C value\n",
    "best_C = lasso_results_df.loc[lasso_results_df['Test_Score'].idxmax(), 'C']\n",
    "print(f\"\\nBest C value: {best_C}\")\n",
    "\n",
    "# Fit final model with best C\n",
    "lasso_final = LogisticRegression(penalty='l1', C=best_C, solver='liblinear', \n",
    "                                  max_iter=1000, random_state=RANDOM_STATE)\n",
    "lasso_final.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get feature importance\n",
    "lasso_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': lasso_final.coef_[0],\n",
    "    'Abs_Coefficient': np.abs(lasso_final.coef_[0])\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nLasso Feature Coefficients:\")\n",
    "print(lasso_importance)\n",
    "\n",
    "# Selected features (non-zero coefficients)\n",
    "selected_features_lasso = lasso_importance[lasso_importance['Coefficient'] != 0]['Feature'].tolist()\n",
    "print(f\"\\nSelected features by Lasso: {len(selected_features_lasso)}\")\n",
    "print(selected_features_lasso)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['green' if c != 0 else 'red' for c in lasso_importance['Coefficient']]\n",
    "plt.barh(lasso_importance['Feature'], lasso_importance['Coefficient'], \n",
    "         color=colors, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Lasso Coefficient', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.title(f'Lasso Feature Coefficients (C={best_C})', fontsize=14, fontweight='bold')\n",
    "plt.axvline(0, color='black', linewidth=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comprehensive Feature Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all feature importance scores\n",
    "print(\"Comprehensive Feature Ranking\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Normalize all scores to 0-1 range\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_norm = MinMaxScaler()\n",
    "\n",
    "# Create comprehensive dataframe\n",
    "comprehensive_ranking = pd.DataFrame({'Feature': X_train.columns})\n",
    "\n",
    "# Add Chi-Square scores\n",
    "comprehensive_ranking = comprehensive_ranking.merge(\n",
    "    chi2_results[['Feature', 'Chi2_Score']].rename(columns={'Chi2_Score': 'Chi2'}),\n",
    "    on='Feature', how='left'\n",
    ")\n",
    "\n",
    "# Add F-scores\n",
    "comprehensive_ranking = comprehensive_ranking.merge(\n",
    "    f_results[['Feature', 'F_Score']].rename(columns={'F_Score': 'ANOVA_F'}),\n",
    "    on='Feature', how='left'\n",
    ")\n",
    "\n",
    "# Add Mutual Information\n",
    "comprehensive_ranking = comprehensive_ranking.merge(\n",
    "    mi_results[['Feature', 'MI_Score']].rename(columns={'MI_Score': 'Mutual_Info'}),\n",
    "    on='Feature', how='left'\n",
    ")\n",
    "\n",
    "# Add Correlation\n",
    "comprehensive_ranking = comprehensive_ranking.merge(\n",
    "    corr_df[['Feature', 'Abs_Correlation']].rename(columns={'Abs_Correlation': 'Correlation'}),\n",
    "    on='Feature', how='left'\n",
    ")\n",
    "\n",
    "# Add Random Forest importance\n",
    "comprehensive_ranking = comprehensive_ranking.merge(\n",
    "    rf_importance[['Feature', 'Importance']].rename(columns={'Importance': 'RF_Importance'}),\n",
    "    on='Feature', how='left'\n",
    ")\n",
    "\n",
    "# Add Gradient Boosting importance\n",
    "comprehensive_ranking = comprehensive_ranking.merge(\n",
    "    gb_importance[['Feature', 'Importance']].rename(columns={'Importance': 'GB_Importance'}),\n",
    "    on='Feature', how='left'\n",
    ")\n",
    "\n",
    "# Add Extra Trees importance\n",
    "comprehensive_ranking = comprehensive_ranking.merge(\n",
    "    et_importance[['Feature', 'Importance']].rename(columns={'Importance': 'ET_Importance'}),\n",
    "    on='Feature', how='left'\n",
    ")\n",
    "\n",
    "# Add Permutation importance\n",
    "comprehensive_ranking = comprehensive_ranking.merge(\n",
    "    perm_importance_df[['Feature', 'Importance_Mean']].rename(columns={'Importance_Mean': 'Perm_Importance'}),\n",
    "    on='Feature', how='left'\n",
    ")\n",
    "\n",
    "# Add Lasso coefficients\n",
    "comprehensive_ranking = comprehensive_ranking.merge(\n",
    "    lasso_importance[['Feature', 'Abs_Coefficient']].rename(columns={'Abs_Coefficient': 'Lasso_Coef'}),\n",
    "    on='Feature', how='left'\n",
    ")\n",
    "\n",
    "# Normalize all scores\n",
    "score_columns = ['Chi2', 'ANOVA_F', 'Mutual_Info', 'Correlation', \n",
    "                 'RF_Importance', 'GB_Importance', 'ET_Importance', \n",
    "                 'Perm_Importance', 'Lasso_Coef']\n",
    "\n",
    "for col in score_columns:\n",
    "    comprehensive_ranking[f'{col}_Norm'] = scaler_norm.fit_transform(\n",
    "        comprehensive_ranking[[col]]\n",
    "    )\n",
    "\n",
    "# Calculate average rank\n",
    "norm_columns = [f'{col}_Norm' for col in score_columns]\n",
    "comprehensive_ranking['Average_Score'] = comprehensive_ranking[norm_columns].mean(axis=1)\n",
    "comprehensive_ranking['Overall_Rank'] = comprehensive_ranking['Average_Score'].rank(ascending=False)\n",
    "\n",
    "# Sort by average score\n",
    "comprehensive_ranking = comprehensive_ranking.sort_values('Average_Score', ascending=False)\n",
    "\n",
    "print(\"\\nComprehensive Feature Ranking (Top Features):\")\n",
    "print(comprehensive_ranking[['Feature', 'Average_Score', 'Overall_Rank'] + score_columns].head(10))\n",
    "\n",
    "print(\"\\nAll Features:\")\n",
    "print(comprehensive_ranking[['Feature', 'Average_Score', 'Overall_Rank']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comprehensive ranking\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.barh(comprehensive_ranking['Feature'], comprehensive_ranking['Average_Score'], \n",
    "         color='teal', edgecolor='black', alpha=0.8)\n",
    "plt.xlabel('Average Normalized Score', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.title('Comprehensive Feature Ranking (Average of All Methods)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of all feature importance methods\n",
    "plt.figure(figsize=(14, 8))\n",
    "heatmap_data = comprehensive_ranking.set_index('Feature')[norm_columns]\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='YlOrRd', \n",
    "            cbar_kws={'label': 'Normalized Importance'})\n",
    "plt.title('Feature Importance Heatmap - All Methods', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Feature Selection Methods', fontsize=12)\n",
    "plt.ylabel('Features', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Feature Selection Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top features based on different criteria\n",
    "print(\"Feature Selection Recommendations\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Top 5 features\n",
    "top_5_features = comprehensive_ranking.head(5)['Feature'].tolist()\n",
    "print(f\"\\nTop 5 Features (by comprehensive ranking):\")\n",
    "for i, feat in enumerate(top_5_features, 1):\n",
    "    score = comprehensive_ranking[comprehensive_ranking['Feature'] == feat]['Average_Score'].values[0]\n",
    "    print(f\"  {i}. {feat} (Score: {score:.4f})\")\n",
    "\n",
    "# Top 70% of features by cumulative importance\n",
    "comprehensive_ranking['Cumulative_Score'] = comprehensive_ranking['Average_Score'].cumsum() / comprehensive_ranking['Average_Score'].sum()\n",
    "top_70_features = comprehensive_ranking[comprehensive_ranking['Cumulative_Score'] <= 0.7]['Feature'].tolist()\n",
    "print(f\"\\nTop features covering 70% cumulative importance: {len(top_70_features)}\")\n",
    "print(top_70_features)\n",
    "\n",
    "# Features selected by majority of methods (appears in at least 5 out of 9 methods as top 50%)\n",
    "print(\"\\nFeatures consistently ranked high across methods:\")\n",
    "threshold = 0.5\n",
    "consistently_high = []\n",
    "for feat in comprehensive_ranking['Feature']:\n",
    "    count = 0\n",
    "    for col in norm_columns:\n",
    "        if comprehensive_ranking[comprehensive_ranking['Feature'] == feat][col].values[0] >= threshold:\n",
    "            count += 1\n",
    "    if count >= 5:\n",
    "        consistently_high.append(feat)\n",
    "\n",
    "print(f\"Features ranked in top 50% by at least 5 methods: {len(consistently_high)}\")\n",
    "print(consistently_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature selection results\n",
    "comprehensive_ranking.to_csv('feature_selection_results.csv', index=False)\n",
    "print(\"\\nFeature selection results saved to 'feature_selection_results.csv'\")\n",
    "\n",
    "# Save top features for modeling\n",
    "selected_features = {\n",
    "    'top_5': top_5_features,\n",
    "    'top_70_cumulative': top_70_features,\n",
    "    'consistently_high': consistently_high,\n",
    "    'rfe_logistic': selected_features_rfe,\n",
    "    'rfe_random_forest': selected_features_rfe_rf,\n",
    "    'lasso': selected_features_lasso\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('selected_features.json', 'w') as f:\n",
    "    json.dump(selected_features, f, indent=2)\n",
    "\n",
    "print(\"Selected features saved to 'selected_features.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FEATURE SELECTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. TOTAL FEATURES ANALYZED:\")\n",
    "print(f\"   - Original features: {len(X_encoded.columns)}\")\n",
    "print(f\"   - Numerical features: {len(numerical_features)}\")\n",
    "print(f\"   - Categorical features: {len(categorical_features)}\")\n",
    "\n",
    "print(\"\\n2. STATISTICAL TESTS:\")\n",
    "print(f\"   - Chi-Square: {(chi2_results['Significant'] == 'Yes').sum()} significant features (p < 0.05)\")\n",
    "print(f\"   - ANOVA F-Test: {(f_results['Significant'] == 'Yes').sum()} significant features (p < 0.05)\")\n",
    "print(f\"   - Mutual Information: All features analyzed\")\n",
    "\n",
    "print(\"\\n3. WRAPPER METHODS:\")\n",
    "print(f\"   - RFE (Logistic): {len(selected_features_rfe)} features selected\")\n",
    "print(f\"   - RFE (Random Forest): {len(selected_features_rfe_rf)} features selected\")\n",
    "print(f\"   - Sequential Forward Selection: {len(selected_features_sfs)} features selected\")\n",
    "\n",
    "print(\"\\n4. EMBEDDED METHODS:\")\n",
    "print(f\"   - Random Forest: Top feature = {rf_importance.iloc[0]['Feature']} (importance: {rf_importance.iloc[0]['Importance']:.4f})\")\n",
    "print(f\"   - Gradient Boosting: Top feature = {gb_importance.iloc[0]['Feature']} (importance: {gb_importance.iloc[0]['Importance']:.4f})\")\n",
    "print(f\"   - Extra Trees: Top feature = {et_importance.iloc[0]['Feature']} (importance: {et_importance.iloc[0]['Importance']:.4f})\")\n",
    "print(f\"   - Lasso (L1): {len(selected_features_lasso)} features with non-zero coefficients\")\n",
    "\n",
    "print(\"\\n5. COMPREHENSIVE RANKING:\")\n",
    "print(f\"   - Top 5 most important features:\")\n",
    "for i, feat in enumerate(top_5_features, 1):\n",
    "    score = comprehensive_ranking[comprehensive_ranking['Feature'] == feat]['Average_Score'].values[0]\n",
    "    print(f\"     {i}. {feat} (Average Score: {score:.4f})\")\n",
    "\n",
    "print(\"\\n6. RECOMMENDATIONS FOR MODELING:\")\n",
    "print(f\"   - Use top {len(top_5_features)} features for simple models\")\n",
    "print(f\"   - Use top {len(top_70_features)} features (70% cumulative) for balanced performance\")\n",
    "print(f\"   - Use {len(consistently_high)} consistently high-ranked features for robust models\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"END OF FEATURE SELECTION\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
