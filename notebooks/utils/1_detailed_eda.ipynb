{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Exploratory Data Analysis (EDA) - Customer Churn Dataset\n",
    "\n",
    "This notebook provides an in-depth exploratory data analysis of the customer churn dataset, covering:\n",
    "- Data overview and structure\n",
    "- Missing value analysis\n",
    "- Univariate analysis (distributions)\n",
    "- Bivariate analysis (relationships with churn)\n",
    "- Multivariate analysis\n",
    "- Outlier detection\n",
    "- Correlation analysis\n",
    "- Statistical insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, normaltest, kstest, shapiro\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization styles\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('customer_churn_dataset_with_date.csv')\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nNumber of samples: {df.shape[0]:,}\")\n",
    "print(f\"Number of features: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 10 rows of the dataset:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display last few rows\n",
    "print(\"Last 10 rows of the dataset:\")\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sample\n",
    "print(\"Random sample of 10 rows:\")\n",
    "df.sample(10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and non-null counts\n",
    "print(\"Dataset Information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types summary\n",
    "print(\"\\nData Types Summary:\")\n",
    "print(df.dtypes.value_counts())\n",
    "print(\"\\nDetailed breakdown:\")\n",
    "for dtype in df.dtypes.unique():\n",
    "    cols = df.select_dtypes(include=[dtype]).columns.tolist()\n",
    "    print(f\"\\n{dtype}: {len(cols)} columns\")\n",
    "    print(f\"  {cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary for numerical features\n",
    "print(\"Statistical Summary - Numerical Features:\")\n",
    "df.describe(include=[np.number]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary for categorical features\n",
    "print(\"Statistical Summary - Categorical Features:\")\n",
    "df.describe(include=['object']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory usage\n",
    "print(\"Memory Usage:\")\n",
    "memory_usage = df.memory_usage(deep=True)\n",
    "print(memory_usage)\n",
    "print(f\"\\nTotal memory usage: {memory_usage.sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values count and percentage\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df)) * 100,\n",
    "    'Data_Type': df.dtypes\n",
    "})\n",
    "\n",
    "missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Percentage', ascending=False)\n",
    "print(\"Missing Values Summary:\")\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "if len(missing_df) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "    \n",
    "    # Bar plot of missing values\n",
    "    missing_df.sort_values('Missing_Count', ascending=True).plot(\n",
    "        kind='barh', x='Column', y='Missing_Count', ax=axes[0], color='coral', legend=False\n",
    "    )\n",
    "    axes[0].set_title('Missing Values Count by Feature', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Count of Missing Values')\n",
    "    axes[0].set_ylabel('Features')\n",
    "    \n",
    "    # Percentage plot\n",
    "    missing_df.sort_values('Missing_Percentage', ascending=True).plot(\n",
    "        kind='barh', x='Column', y='Missing_Percentage', ax=axes[1], color='skyblue', legend=False\n",
    "    )\n",
    "    axes[1].set_title('Missing Values Percentage by Feature', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Percentage (%)')\n",
    "    axes[1].set_ylabel('Features')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No missing values found in the dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing value heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.isnull(), cbar=True, yticklabels=False, cmap='viridis')\n",
    "plt.title('Missing Values Heatmap', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing value patterns\n",
    "print(\"Missing Value Patterns:\")\n",
    "print(f\"Total rows with at least one missing value: {df.isnull().any(axis=1).sum():,}\")\n",
    "print(f\"Percentage: {(df.isnull().any(axis=1).sum() / len(df)) * 100:.2f}%\")\n",
    "print(f\"\\nRows with all values present: {(~df.isnull().any(axis=1)).sum():,}\")\n",
    "print(f\"Percentage: {((~df.isnull().any(axis=1)).sum() / len(df)) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn distribution\n",
    "churn_counts = df['churn'].value_counts()\n",
    "churn_pct = df['churn'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Churn Distribution:\")\n",
    "churn_summary = pd.DataFrame({\n",
    "    'Count': churn_counts,\n",
    "    'Percentage': churn_pct\n",
    "})\n",
    "print(churn_summary)\n",
    "\n",
    "print(f\"\\nChurn Rate: {churn_pct[1]:.2f}%\")\n",
    "print(f\"Retention Rate: {churn_pct[0]:.2f}%\")\n",
    "print(f\"\\nClass Imbalance Ratio: 1:{churn_counts[0]/churn_counts[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize churn distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Count plot\n",
    "sns.countplot(data=df, x='churn', ax=axes[0], palette='Set2')\n",
    "axes[0].set_title('Churn Distribution - Count', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Churn (0=No, 1=Yes)')\n",
    "axes[0].set_ylabel('Count')\n",
    "for container in axes[0].containers:\n",
    "    axes[0].bar_label(container)\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#90EE90', '#FF6B6B']\n",
    "axes[1].pie(churn_counts, labels=['Retained (0)', 'Churned (1)'], autopct='%1.1f%%', \n",
    "            startangle=90, colors=colors, explode=(0, 0.1))\n",
    "axes[1].set_title('Churn Distribution - Percentage', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Percentage bar plot\n",
    "churn_pct.plot(kind='bar', ax=axes[2], color=['#90EE90', '#FF6B6B'])\n",
    "axes[2].set_title('Churn Distribution - Percentage', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Churn (0=No, 1=Yes)')\n",
    "axes[2].set_ylabel('Percentage (%)')\n",
    "axes[2].set_xticklabels(['Retained (0)', 'Churned (1)'], rotation=0)\n",
    "for container in axes[2].containers:\n",
    "    axes[2].bar_label(container, fmt='%.1f%%')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Univariate Analysis - Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical columns (excluding customer_id and churn)\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numerical_cols = [col for col in numerical_cols if col not in ['customer_id', 'churn']]\n",
    "\n",
    "print(f\"Numerical features: {numerical_cols}\")\n",
    "print(f\"Total: {len(numerical_cols)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed statistics for each numerical feature\n",
    "print(\"Detailed Statistics for Numerical Features:\\n\")\n",
    "for col in numerical_cols:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Feature: {col.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Remove missing values for analysis\n",
    "    data = df[col].dropna()\n",
    "    \n",
    "    print(f\"Count: {len(data):,}\")\n",
    "    print(f\"Missing: {df[col].isnull().sum():,}\")\n",
    "    print(f\"\\nCentral Tendency:\")\n",
    "    print(f\"  Mean: {data.mean():.3f}\")\n",
    "    print(f\"  Median: {data.median():.3f}\")\n",
    "    print(f\"  Mode: {data.mode().values[0] if len(data.mode()) > 0 else 'N/A'}\")\n",
    "    \n",
    "    print(f\"\\nDispersion:\")\n",
    "    print(f\"  Std Dev: {data.std():.3f}\")\n",
    "    print(f\"  Variance: {data.var():.3f}\")\n",
    "    print(f\"  Range: {data.max() - data.min():.3f}\")\n",
    "    print(f\"  IQR: {data.quantile(0.75) - data.quantile(0.25):.3f}\")\n",
    "    print(f\"  Coefficient of Variation: {(data.std() / data.mean() * 100):.2f}%\")\n",
    "    \n",
    "    print(f\"\\nShape:\")\n",
    "    print(f\"  Skewness: {data.skew():.3f}\")\n",
    "    print(f\"  Kurtosis: {data.kurtosis():.3f}\")\n",
    "    \n",
    "    print(f\"\\nQuantiles:\")\n",
    "    print(f\"  Min: {data.min():.3f}\")\n",
    "    print(f\"  Q1 (25%): {data.quantile(0.25):.3f}\")\n",
    "    print(f\"  Q2 (50%): {data.quantile(0.50):.3f}\")\n",
    "    print(f\"  Q3 (75%): {data.quantile(0.75):.3f}\")\n",
    "    print(f\"  Max: {data.max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots for numerical features\n",
    "fig, axes = plt.subplots(len(numerical_cols), 3, figsize=(18, 5*len(numerical_cols)))\n",
    "\n",
    "if len(numerical_cols) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    data = df[col].dropna()\n",
    "    \n",
    "    # Histogram with KDE\n",
    "    axes[idx, 0].hist(data, bins=50, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "    axes[idx, 0].set_title(f'{col} - Histogram', fontweight='bold')\n",
    "    axes[idx, 0].set_xlabel(col)\n",
    "    axes[idx, 0].set_ylabel('Frequency')\n",
    "    axes[idx, 0].axvline(data.mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    axes[idx, 0].axvline(data.median(), color='green', linestyle='--', linewidth=2, label='Median')\n",
    "    axes[idx, 0].legend()\n",
    "    \n",
    "    # Box plot\n",
    "    axes[idx, 1].boxplot(data, vert=True, patch_artist=True,\n",
    "                         boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                         medianprops=dict(color='red', linewidth=2))\n",
    "    axes[idx, 1].set_title(f'{col} - Box Plot', fontweight='bold')\n",
    "    axes[idx, 1].set_ylabel(col)\n",
    "    axes[idx, 1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Q-Q plot\n",
    "    stats.probplot(data, dist=\"norm\", plot=axes[idx, 2])\n",
    "    axes[idx, 2].set_title(f'{col} - Q-Q Plot', fontweight='bold')\n",
    "    axes[idx, 2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plots for numerical features\n",
    "fig, axes = plt.subplots(1, len(numerical_cols), figsize=(6*len(numerical_cols), 6))\n",
    "\n",
    "if len(numerical_cols) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    sns.violinplot(y=df[col], ax=axes[idx], color='lightcoral')\n",
    "    axes[idx].set_title(f'{col} - Violin Plot', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel(col)\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Univariate Analysis - Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns (excluding Date and customer_id)\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_cols = [col for col in categorical_cols if col not in ['Date', 'customer_id']]\n",
    "\n",
    "print(f\"Categorical features: {categorical_cols}\")\n",
    "print(f\"Total: {len(categorical_cols)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of categorical features\n",
    "print(\"Detailed Analysis of Categorical Features:\\n\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Feature: {col.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    value_counts = df[col].value_counts()\n",
    "    value_pct = df[col].value_counts(normalize=True) * 100\n",
    "    \n",
    "    summary = pd.DataFrame({\n",
    "        'Count': value_counts,\n",
    "        'Percentage': value_pct\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nUnique values: {df[col].nunique()}\")\n",
    "    print(f\"Missing values: {df[col].isnull().sum()}\")\n",
    "    print(f\"\\nValue Distribution:\")\n",
    "    print(summary)\n",
    "    print(f\"\\nMode: {df[col].mode().values[0] if len(df[col].mode()) > 0 else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize categorical features\n",
    "fig, axes = plt.subplots(len(categorical_cols), 2, figsize=(16, 5*len(categorical_cols)))\n",
    "\n",
    "if len(categorical_cols) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for idx, col in enumerate(categorical_cols):\n",
    "    # Count plot\n",
    "    value_counts = df[col].value_counts()\n",
    "    sns.countplot(data=df, x=col, ax=axes[idx, 0], palette='Set3', order=value_counts.index)\n",
    "    axes[idx, 0].set_title(f'{col} - Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[idx, 0].set_xlabel(col)\n",
    "    axes[idx, 0].set_ylabel('Count')\n",
    "    axes[idx, 0].tick_params(axis='x', rotation=45)\n",
    "    for container in axes[idx, 0].containers:\n",
    "        axes[idx, 0].bar_label(container)\n",
    "    \n",
    "    # Pie chart\n",
    "    axes[idx, 1].pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[idx, 1].set_title(f'{col} - Percentage Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bivariate Analysis - Numerical Features vs Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical comparison between churned and retained customers\n",
    "print(\"Numerical Features Comparison: Churned vs Retained Customers\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for col in numerical_cols:\n",
    "    print(f\"\\nFeature: {col.upper()}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    churned = df[df['churn'] == 1][col].dropna()\n",
    "    retained = df[df['churn'] == 0][col].dropna()\n",
    "    \n",
    "    print(f\"\\nRetained Customers (n={len(retained)}):\")\n",
    "    print(f\"  Mean: {retained.mean():.3f}\")\n",
    "    print(f\"  Median: {retained.median():.3f}\")\n",
    "    print(f\"  Std: {retained.std():.3f}\")\n",
    "    \n",
    "    print(f\"\\nChurned Customers (n={len(churned)}):\")\n",
    "    print(f\"  Mean: {churned.mean():.3f}\")\n",
    "    print(f\"  Median: {churned.median():.3f}\")\n",
    "    print(f\"  Std: {churned.std():.3f}\")\n",
    "    \n",
    "    print(f\"\\nDifference:\")\n",
    "    print(f\"  Mean Difference: {churned.mean() - retained.mean():.3f}\")\n",
    "    print(f\"  Percentage Change: {((churned.mean() - retained.mean()) / retained.mean() * 100):.2f}%\")\n",
    "    \n",
    "    # Mann-Whitney U test (non-parametric)\n",
    "    statistic, p_value = stats.mannwhitneyu(retained, churned, alternative='two-sided')\n",
    "    print(f\"\\nMann-Whitney U Test:\")\n",
    "    print(f\"  Test Statistic: {statistic:.3f}\")\n",
    "    print(f\"  P-value: {p_value:.6f}\")\n",
    "    print(f\"  Significant at α=0.05: {'Yes' if p_value < 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots: Numerical features by churn status\n",
    "fig, axes = plt.subplots(2, len(numerical_cols), figsize=(6*len(numerical_cols), 12))\n",
    "\n",
    "if len(numerical_cols) == 1:\n",
    "    axes = axes.reshape(-1, 1)\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    # Box plot\n",
    "    sns.boxplot(data=df, x='churn', y=col, ax=axes[0, idx], palette='Set2')\n",
    "    axes[0, idx].set_title(f'{col} by Churn Status - Box Plot', fontweight='bold')\n",
    "    axes[0, idx].set_xlabel('Churn (0=No, 1=Yes)')\n",
    "    axes[0, idx].set_ylabel(col)\n",
    "    axes[0, idx].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Violin plot\n",
    "    sns.violinplot(data=df, x='churn', y=col, ax=axes[1, idx], palette='Set1')\n",
    "    axes[1, idx].set_title(f'{col} by Churn Status - Violin Plot', fontweight='bold')\n",
    "    axes[1, idx].set_xlabel('Churn (0=No, 1=Yes)')\n",
    "    axes[1, idx].set_ylabel(col)\n",
    "    axes[1, idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution comparison: Churned vs Retained\n",
    "fig, axes = plt.subplots(len(numerical_cols), 1, figsize=(14, 5*len(numerical_cols)))\n",
    "\n",
    "if len(numerical_cols) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    churned = df[df['churn'] == 1][col].dropna()\n",
    "    retained = df[df['churn'] == 0][col].dropna()\n",
    "    \n",
    "    axes[idx].hist(retained, bins=50, alpha=0.5, label='Retained (0)', color='green', edgecolor='black')\n",
    "    axes[idx].hist(churned, bins=50, alpha=0.5, label='Churned (1)', color='red', edgecolor='black')\n",
    "    axes[idx].set_title(f'{col} Distribution: Churned vs Retained', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Bivariate Analysis - Categorical Features vs Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features vs Churn - Statistical analysis\n",
    "print(\"Categorical Features vs Churn - Chi-Square Test\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\nFeature: {col.upper()}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Create contingency table\n",
    "    contingency_table = pd.crosstab(df[col], df['churn'])\n",
    "    print(\"\\nContingency Table:\")\n",
    "    print(contingency_table)\n",
    "    \n",
    "    # Chi-square test\n",
    "    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "    \n",
    "    print(f\"\\nChi-Square Test Results:\")\n",
    "    print(f\"  Chi-Square Statistic: {chi2:.3f}\")\n",
    "    print(f\"  P-value: {p_value:.6f}\")\n",
    "    print(f\"  Degrees of Freedom: {dof}\")\n",
    "    print(f\"  Significant at α=0.05: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "    \n",
    "    # Cramér's V (effect size)\n",
    "    n = contingency_table.sum().sum()\n",
    "    cramers_v = np.sqrt(chi2 / (n * (min(contingency_table.shape) - 1)))\n",
    "    print(f\"  Cramér's V: {cramers_v:.3f}\")\n",
    "    \n",
    "    # Churn rate by category\n",
    "    churn_rate = df.groupby(col)['churn'].agg(['sum', 'count', 'mean'])\n",
    "    churn_rate.columns = ['Churned_Count', 'Total_Count', 'Churn_Rate']\n",
    "    churn_rate['Churn_Rate'] = churn_rate['Churn_Rate'] * 100\n",
    "    print(\"\\nChurn Rate by Category:\")\n",
    "    print(churn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize categorical features vs churn\n",
    "fig, axes = plt.subplots(len(categorical_cols), 2, figsize=(16, 5*len(categorical_cols)))\n",
    "\n",
    "if len(categorical_cols) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for idx, col in enumerate(categorical_cols):\n",
    "    # Stacked bar chart\n",
    "    churn_cross = pd.crosstab(df[col], df['churn'], normalize='index') * 100\n",
    "    churn_cross.plot(kind='bar', stacked=True, ax=axes[idx, 0], color=['#90EE90', '#FF6B6B'])\n",
    "    axes[idx, 0].set_title(f'{col} vs Churn - Stacked Percentage', fontsize=14, fontweight='bold')\n",
    "    axes[idx, 0].set_xlabel(col)\n",
    "    axes[idx, 0].set_ylabel('Percentage (%)')\n",
    "    axes[idx, 0].legend(['Retained (0)', 'Churned (1)'], loc='best')\n",
    "    axes[idx, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[idx, 0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Grouped bar chart\n",
    "    churn_cross_counts = pd.crosstab(df[col], df['churn'])\n",
    "    churn_cross_counts.plot(kind='bar', ax=axes[idx, 1], color=['#90EE90', '#FF6B6B'])\n",
    "    axes[idx, 1].set_title(f'{col} vs Churn - Count', fontsize=14, fontweight='bold')\n",
    "    axes[idx, 1].set_xlabel(col)\n",
    "    axes[idx, 1].set_ylabel('Count')\n",
    "    axes[idx, 1].legend(['Retained (0)', 'Churned (1)'], loc='best')\n",
    "    axes[idx, 1].tick_params(axis='x', rotation=45)\n",
    "    axes[idx, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn rate by categorical feature\n",
    "fig, axes = plt.subplots(1, len(categorical_cols), figsize=(7*len(categorical_cols), 6))\n",
    "\n",
    "if len(categorical_cols) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, col in enumerate(categorical_cols):\n",
    "    churn_rate = df.groupby(col)['churn'].mean() * 100\n",
    "    churn_rate.sort_values(ascending=False).plot(kind='bar', ax=axes[idx], color='coral')\n",
    "    axes[idx].set_title(f'Churn Rate by {col}', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Churn Rate (%)')\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "    axes[idx].axhline(df['churn'].mean()*100, color='red', linestyle='--', \n",
    "                      linewidth=2, label=f'Overall: {df[\"churn\"].mean()*100:.1f}%')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "    for container in axes[idx].containers:\n",
    "        axes[idx].bar_label(container, fmt='%.1f%%')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for numerical features\n",
    "corr_matrix = df[numerical_cols + ['churn']].corr()\n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "print(corr_matrix)\n",
    "\n",
    "# Correlation with target variable\n",
    "print(\"\\nCorrelation with Churn (sorted by absolute value):\")\n",
    "churn_corr = corr_matrix['churn'].drop('churn').sort_values(key=abs, ascending=False)\n",
    "print(churn_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix Heatmap', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with churn - bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "churn_corr_abs = churn_corr.abs().sort_values(ascending=True)\n",
    "colors = ['green' if x > 0 else 'red' for x in churn_corr[churn_corr_abs.index]]\n",
    "churn_corr[churn_corr_abs.index].plot(kind='barh', color=colors, edgecolor='black')\n",
    "plt.title('Correlation of Features with Churn', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.ylabel('Features')\n",
    "plt.axvline(0, color='black', linewidth=0.8)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plot for numerical features (sample for performance)\n",
    "sample_df = df.sample(n=min(1000, len(df)), random_state=42)\n",
    "sns.pairplot(sample_df[numerical_cols + ['churn']], hue='churn', palette='Set1', \n",
    "             diag_kind='kde', plot_kws={'alpha': 0.6})\n",
    "plt.suptitle('Pair Plot - Numerical Features (Sample)', y=1.02, fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots matrix\n",
    "if len(numerical_cols) >= 2:\n",
    "    from itertools import combinations\n",
    "    \n",
    "    # Get all pairs of numerical features\n",
    "    feature_pairs = list(combinations(numerical_cols, 2))\n",
    "    \n",
    "    # Limit to first 6 pairs for visualization\n",
    "    n_pairs = min(6, len(feature_pairs))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, (feat1, feat2) in enumerate(feature_pairs[:n_pairs]):\n",
    "        for churn_val in [0, 1]:\n",
    "            subset = df[df['churn'] == churn_val]\n",
    "            axes[idx].scatter(subset[feat1], subset[feat2], \n",
    "                            label=f'Churn={churn_val}', alpha=0.5, s=20)\n",
    "        \n",
    "        axes[idx].set_xlabel(feat1, fontsize=10)\n",
    "        axes[idx].set_ylabel(feat2, fontsize=10)\n",
    "        axes[idx].set_title(f'{feat1} vs {feat2}', fontweight='bold')\n",
    "        axes[idx].legend()\n",
    "        axes[idx].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D scatter plot (if we have at least 3 numerical features)\n",
    "if len(numerical_cols) >= 3:\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    \n",
    "    fig = plt.figure(figsize=(14, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    sample_df = df.sample(n=min(5000, len(df)), random_state=42)\n",
    "    \n",
    "    colors = ['green' if x == 0 else 'red' for x in sample_df['churn']]\n",
    "    ax.scatter(sample_df[numerical_cols[0]], \n",
    "               sample_df[numerical_cols[1]], \n",
    "               sample_df[numerical_cols[2]], \n",
    "               c=colors, alpha=0.5, s=20)\n",
    "    \n",
    "    ax.set_xlabel(numerical_cols[0], fontsize=10)\n",
    "    ax.set_ylabel(numerical_cols[1], fontsize=10)\n",
    "    ax.set_zlabel(numerical_cols[2], fontsize=10)\n",
    "    ax.set_title(f'3D Scatter: {numerical_cols[0]} vs {numerical_cols[1]} vs {numerical_cols[2]}',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Create custom legend\n",
    "    from matplotlib.lines import Line2D\n",
    "    legend_elements = [Line2D([0], [0], marker='o', color='w', \n",
    "                              markerfacecolor='green', markersize=10, label='Retained'),\n",
    "                      Line2D([0], [0], marker='o', color='w', \n",
    "                              markerfacecolor='red', markersize=10, label='Churned')]\n",
    "    ax.legend(handles=legend_elements)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Outlier Detection and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection using IQR method\n",
    "print(\"Outlier Detection using IQR Method\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "outlier_summary = []\n",
    "\n",
    "for col in numerical_cols:\n",
    "    data = df[col].dropna()\n",
    "    \n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "    \n",
    "    print(f\"\\nFeature: {col.upper()}\")\n",
    "    print(f\"  Q1: {Q1:.3f}\")\n",
    "    print(f\"  Q3: {Q3:.3f}\")\n",
    "    print(f\"  IQR: {IQR:.3f}\")\n",
    "    print(f\"  Lower Bound: {lower_bound:.3f}\")\n",
    "    print(f\"  Upper Bound: {upper_bound:.3f}\")\n",
    "    print(f\"  Number of Outliers: {len(outliers):,}\")\n",
    "    print(f\"  Percentage of Outliers: {(len(outliers) / len(data) * 100):.2f}%\")\n",
    "    \n",
    "    outlier_summary.append({\n",
    "        'Feature': col,\n",
    "        'Outlier_Count': len(outliers),\n",
    "        'Outlier_Percentage': (len(outliers) / len(data) * 100),\n",
    "        'Lower_Bound': lower_bound,\n",
    "        'Upper_Bound': upper_bound\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nOutlier Summary:\")\n",
    "print(outlier_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outliers\n",
    "fig, axes = plt.subplots(1, len(numerical_cols), figsize=(6*len(numerical_cols), 6))\n",
    "\n",
    "if len(numerical_cols) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    data = df[col].dropna()\n",
    "    \n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Box plot with outliers highlighted\n",
    "    bp = axes[idx].boxplot(data, vert=True, patch_artist=True,\n",
    "                           boxprops=dict(facecolor='lightblue'),\n",
    "                           flierprops=dict(marker='o', markerfacecolor='red', \n",
    "                                         markersize=5, alpha=0.5))\n",
    "    \n",
    "    axes[idx].set_title(f'{col} - Outlier Detection', fontweight='bold')\n",
    "    axes[idx].set_ylabel(col)\n",
    "    axes[idx].axhline(lower_bound, color='orange', linestyle='--', \n",
    "                      linewidth=2, label='Lower Bound')\n",
    "    axes[idx].axhline(upper_bound, color='orange', linestyle='--', \n",
    "                      linewidth=2, label='Upper Bound')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score method for outlier detection\n",
    "print(\"Outlier Detection using Z-Score Method (|z| > 3)\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for col in numerical_cols:\n",
    "    data = df[col].dropna()\n",
    "    z_scores = np.abs(stats.zscore(data))\n",
    "    outliers = data[z_scores > 3]\n",
    "    \n",
    "    print(f\"\\nFeature: {col.upper()}\")\n",
    "    print(f\"  Number of Outliers (|z| > 3): {len(outliers):,}\")\n",
    "    print(f\"  Percentage: {(len(outliers) / len(data) * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Normality Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normality tests for numerical features\n",
    "print(\"Normality Tests for Numerical Features\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "normality_results = []\n",
    "\n",
    "for col in numerical_cols:\n",
    "    data = df[col].dropna()\n",
    "    \n",
    "    # Sample for large datasets (Shapiro-Wilk works best with n < 5000)\n",
    "    if len(data) > 5000:\n",
    "        sample_data = data.sample(5000, random_state=42)\n",
    "    else:\n",
    "        sample_data = data\n",
    "    \n",
    "    print(f\"\\nFeature: {col.upper()}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Shapiro-Wilk test\n",
    "    stat_sw, p_sw = shapiro(sample_data)\n",
    "    print(f\"\\nShapiro-Wilk Test:\")\n",
    "    print(f\"  Test Statistic: {stat_sw:.6f}\")\n",
    "    print(f\"  P-value: {p_sw:.6f}\")\n",
    "    print(f\"  Normal at α=0.05: {'Yes' if p_sw > 0.05 else 'No'}\")\n",
    "    \n",
    "    # Kolmogorov-Smirnov test\n",
    "    stat_ks, p_ks = kstest(data, 'norm', args=(data.mean(), data.std()))\n",
    "    print(f\"\\nKolmogorov-Smirnov Test:\")\n",
    "    print(f\"  Test Statistic: {stat_ks:.6f}\")\n",
    "    print(f\"  P-value: {p_ks:.6f}\")\n",
    "    print(f\"  Normal at α=0.05: {'Yes' if p_ks > 0.05 else 'No'}\")\n",
    "    \n",
    "    # D'Agostino's K-squared test\n",
    "    if len(data) >= 8:  # Minimum sample size for this test\n",
    "        stat_da, p_da = normaltest(data)\n",
    "        print(f\"\\nD'Agostino-Pearson Test:\")\n",
    "        print(f\"  Test Statistic: {stat_da:.6f}\")\n",
    "        print(f\"  P-value: {p_da:.6f}\")\n",
    "        print(f\"  Normal at α=0.05: {'Yes' if p_da > 0.05 else 'No'}\")\n",
    "    \n",
    "    normality_results.append({\n",
    "        'Feature': col,\n",
    "        'Shapiro_Wilk_p': p_sw,\n",
    "        'KS_Test_p': p_ks,\n",
    "        'Is_Normal': 'Yes' if (p_sw > 0.05 and p_ks > 0.05) else 'No'\n",
    "    })\n",
    "\n",
    "normality_df = pd.DataFrame(normality_results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nNormality Test Summary:\")\n",
    "print(normality_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Time Series Analysis (if Date column is meaningful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Churn over time\n",
    "churn_over_time = df.groupby('Date')['churn'].agg(['sum', 'count', 'mean']).reset_index()\n",
    "churn_over_time.columns = ['Date', 'Churned_Count', 'Total_Count', 'Churn_Rate']\n",
    "churn_over_time['Churn_Rate'] = churn_over_time['Churn_Rate'] * 100\n",
    "\n",
    "print(\"Churn Over Time - First 10 Days:\")\n",
    "print(churn_over_time.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot churn over time\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# Churn count over time\n",
    "axes[0].plot(churn_over_time['Date'], churn_over_time['Churned_Count'], \n",
    "             marker='o', linewidth=2, markersize=4, color='red')\n",
    "axes[0].set_title('Number of Churned Customers Over Time', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Churn rate over time\n",
    "axes[1].plot(churn_over_time['Date'], churn_over_time['Churn_Rate'], \n",
    "             marker='o', linewidth=2, markersize=4, color='blue')\n",
    "axes[1].axhline(df['churn'].mean()*100, color='red', linestyle='--', \n",
    "                linewidth=2, label=f'Overall: {df[\"churn\"].mean()*100:.2f}%')\n",
    "axes[1].set_title('Churn Rate Over Time', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Churn Rate (%)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Key Insights and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"KEY INSIGHTS FROM EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. DATASET OVERVIEW:\")\n",
    "print(f\"   - Total Records: {len(df):,}\")\n",
    "print(f\"   - Total Features: {df.shape[1]}\")\n",
    "print(f\"   - Numerical Features: {len(numerical_cols)}\")\n",
    "print(f\"   - Categorical Features: {len(categorical_cols)}\")\n",
    "\n",
    "print(\"\\n2. TARGET VARIABLE (CHURN):\")\n",
    "print(f\"   - Churn Rate: {df['churn'].mean()*100:.2f}%\")\n",
    "print(f\"   - Retention Rate: {(1-df['churn'].mean())*100:.2f}%\")\n",
    "print(f\"   - Class Imbalance Ratio: 1:{df['churn'].value_counts()[0]/df['churn'].value_counts()[1]:.2f}\")\n",
    "\n",
    "print(\"\\n3. MISSING VALUES:\")\n",
    "total_missing = df.isnull().sum().sum()\n",
    "if total_missing > 0:\n",
    "    print(f\"   - Total Missing Values: {total_missing:,}\")\n",
    "    print(f\"   - Features with Missing Values: {(df.isnull().sum() > 0).sum()}\")\n",
    "    print(f\"   - Percentage of Data Missing: {(total_missing / (df.shape[0] * df.shape[1]) * 100):.2f}%\")\n",
    "else:\n",
    "    print(\"   - No missing values detected\")\n",
    "\n",
    "print(\"\\n4. CORRELATIONS WITH CHURN:\")\n",
    "print(\"   Top Features (by absolute correlation):\")\n",
    "churn_corr_sorted = corr_matrix['churn'].drop('churn').abs().sort_values(ascending=False)\n",
    "for i, (feat, corr) in enumerate(churn_corr_sorted.head(5).items(), 1):\n",
    "    print(f\"   {i}. {feat}: {corr:.3f}\")\n",
    "\n",
    "print(\"\\n5. OUTLIERS:\")\n",
    "print(\"   Features with significant outliers (>5%):\")\n",
    "for _, row in outlier_df[outlier_df['Outlier_Percentage'] > 5].iterrows():\n",
    "    print(f\"   - {row['Feature']}: {row['Outlier_Percentage']:.2f}%\")\n",
    "\n",
    "print(\"\\n6. DISTRIBUTION CHARACTERISTICS:\")\n",
    "for col in numerical_cols:\n",
    "    skew = df[col].skew()\n",
    "    print(f\"   - {col}: Skewness = {skew:.3f} ({'Right-skewed' if skew > 0.5 else 'Left-skewed' if skew < -0.5 else 'Approximately symmetric'})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"END OF EDA\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
